{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrxST22ozElG",
        "outputId": "1394de44-b5dc-4e39-bff2-443923feeed6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d1UMmcdAze7-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "The syntax of the command is incorrect.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "The syntax of the command is incorrect.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-BRxnPIN2HYV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/root/.kaggle\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzcmhE8vzviS",
        "outputId": "ce41be68-41f1-4653-fa8a-7a9a67509e78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "unzip:  cannot find either mnist-dataset.zip or mnist-dataset.zip.zip.\n",
            "unzip:  cannot find either mnist-dataset.zip or mnist-dataset.zip.zip.\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d hojjatk/mnist-dataset\n",
        "!unzip mnist-dataset.zip -d mnist_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGQV08PI0VHc",
        "outputId": "f9f539b9-a4a4-44fb-8cbc-d0c08a526cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000, 10)\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize and reshape for Conv2D\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# add channel dim\n",
        "x_train = np.expand_dims(x_train, -1) # shape (60000, 28, 28, 1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# one-hot labels\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape, y_train_cat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "vTYiFp9N2Nke",
        "outputId": "4569797e-0825-4c1b-d06b-acb8e14b1f81"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">619,114</span> (2.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m619,114\u001b[0m (2.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">617,450</span> (2.36 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m617,450\u001b[0m (2.36 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> (6.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,664\u001b[0m (6.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def make_model(input_shape=(28,28,1), num_classes=10):\n",
        "  inp = layers.Input(shape=input_shape)\n",
        "  \n",
        "  # Block 1\n",
        "  x = layers.Conv2D(32, 3, activation='relu', padding='same')(inp)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPool2D(2)(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  # Block 2\n",
        "  x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPool2D(2)(x)\n",
        "  x = layers.Dropout(0.25)(x)\n",
        "\n",
        "  # Block 3 - Additional depth for better feature extraction\n",
        "  x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.MaxPool2D(2)(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "\n",
        "  # Dense layers with better regularization\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(256, activation='relu')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  \n",
        "  x = layers.Dense(128, activation='relu')(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "  \n",
        "  out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "  model = models.Model(inp, out)\n",
        "  return model\n",
        "\n",
        "model = make_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PGA-uYt2Qu2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mixed precision policy: mixed_float16\n",
            "Compute dtype: float16\n",
            "Variable dtype: float32\n"
          ]
        }
      ],
      "source": [
        "# Enable mixed precision training for faster GPU training\n",
        "from tensorflow.keras import mixed_precision\n",
        "\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "print(f\"Mixed precision policy: {policy.name}\")\n",
        "print(f\"Compute dtype: {policy.compute_dtype}\")\n",
        "print(f\"Variable dtype: {policy.variable_dtype}\")\n",
        "\n",
        "# Compile model with optimizer and loss\n",
        "model.compile(\n",
        "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "loss='categorical_crossentropy',\n",
        "metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# callbacks: checkpoint to Drive\n",
        "drive_path = '/content/drive/MyDrive/mnist_models'\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "checkpoint_path = os.path.join(drive_path, 'mnist_cnn_best.keras')\n",
        "\n",
        "callbacks = [\n",
        "EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
        "ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt-IfuuY2WW8",
        "outputId": "311cdbe4-dd68-4c85-abf7-eb99dafa8355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7154 - loss: 0.9126\n",
            "Epoch 1: val_loss improved from None to 0.04008, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 1: val_loss improved from None to 0.04008, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 49ms/step - accuracy: 0.8642 - loss: 0.4341 - val_accuracy: 0.9875 - val_loss: 0.0401 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "Epoch 2/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 48ms/step - accuracy: 0.9688 - loss: 0.0940"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\MAHADEV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2: val_loss improved from 0.04008 to 0.03972, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0940 - val_accuracy: 0.9872 - val_loss: 0.0397 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "Epoch 3/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9582 - loss: 0.1400\n",
            "Epoch 3: val_loss improved from 0.03972 to 0.03065, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 3: val_loss improved from 0.03972 to 0.03065, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9631 - loss: 0.1240 - val_accuracy: 0.9905 - val_loss: 0.0307 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "Epoch 4/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 46ms/step - accuracy: 0.9688 - loss: 0.0508\n",
            "Epoch 4: val_loss did not improve from 0.03065\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0508 - val_accuracy: 0.9900 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 4: val_loss did not improve from 0.03065\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0508 - val_accuracy: 0.9900 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9728 - loss: 0.0914\n",
            "Epoch 5: val_loss improved from 0.03065 to 0.02236, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 5: val_loss improved from 0.03065 to 0.02236, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 52ms/step - accuracy: 0.9737 - loss: 0.0879 - val_accuracy: 0.9925 - val_loss: 0.0224 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "Epoch 6/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 45ms/step - accuracy: 0.9844 - loss: 0.0894\n",
            "Epoch 6: val_loss improved from 0.02236 to 0.02229, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 6: val_loss improved from 0.02236 to 0.02229, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0894 - val_accuracy: 0.9925 - val_loss: 0.0223 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "Epoch 7/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9766 - loss: 0.0794\n",
            "Epoch 7: val_loss did not improve from 0.02229\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9768 - loss: 0.0772 - val_accuracy: 0.9879 - val_loss: 0.0382 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.02229\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9768 - loss: 0.0772 - val_accuracy: 0.9879 - val_loss: 0.0382 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.1435\n",
            "Epoch 8: val_loss did not improve from 0.02229\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1435 - val_accuracy: 0.9881 - val_loss: 0.0381 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 8: val_loss did not improve from 0.02229\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1435 - val_accuracy: 0.9881 - val_loss: 0.0381 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9789 - loss: 0.0719\n",
            "Epoch 9: val_loss improved from 0.02229 to 0.02207, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 9: val_loss improved from 0.02229 to 0.02207, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9804 - loss: 0.0662 - val_accuracy: 0.9933 - val_loss: 0.0221 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "Epoch 10/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0206\n",
            "Epoch 10: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.9928 - val_loss: 0.0226 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.9928 - val_loss: 0.0226 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9806 - loss: 0.0641\n",
            "Epoch 11: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9809 - loss: 0.0639 - val_accuracy: 0.9913 - val_loss: 0.0288 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9809 - loss: 0.0639 - val_accuracy: 0.9913 - val_loss: 0.0288 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 53ms/step - accuracy: 0.9688 - loss: 0.0800\n",
            "Epoch 12: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0800 - val_accuracy: 0.9906 - val_loss: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0800 - val_accuracy: 0.9906 - val_loss: 0.0299 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9823 - loss: 0.0596\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9841 - loss: 0.0550 - val_accuracy: 0.9907 - val_loss: 0.0286 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9841 - loss: 0.0550 - val_accuracy: 0.9907 - val_loss: 0.0286 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0107\n",
            "Epoch 14: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9906 - val_loss: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.02207\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9906 - val_loss: 0.0287 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9866 - loss: 0.0469\n",
            "Epoch 15: val_loss improved from 0.02207 to 0.01881, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 15: val_loss improved from 0.02207 to 0.01881, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 50ms/step - accuracy: 0.9878 - loss: 0.0429 - val_accuracy: 0.9942 - val_loss: 0.0188 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "Epoch 16/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 9.3951e-04\n",
            "Epoch 16: val_loss did not improve from 0.01881\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3951e-04 - val_accuracy: 0.9941 - val_loss: 0.0190 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 16: val_loss did not improve from 0.01881\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3951e-04 - val_accuracy: 0.9941 - val_loss: 0.0190 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9881 - loss: 0.0395\n",
            "Epoch 17: val_loss improved from 0.01881 to 0.01352, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 17: val_loss improved from 0.01881 to 0.01352, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9880 - loss: 0.0409 - val_accuracy: 0.9956 - val_loss: 0.0135 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "Epoch 18/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0059\n",
            "Epoch 18: val_loss improved from 0.01352 to 0.01347, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 18: val_loss improved from 0.01352 to 0.01347, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9956 - val_loss: 0.0135 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "Epoch 19/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9885 - loss: 0.0385\n",
            "Epoch 19: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9889 - loss: 0.0381 - val_accuracy: 0.9949 - val_loss: 0.0168 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9889 - loss: 0.0381 - val_accuracy: 0.9949 - val_loss: 0.0168 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 20: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9948 - val_loss: 0.0169 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9948 - val_loss: 0.0169 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9898 - loss: 0.0354\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9889 - loss: 0.0379 - val_accuracy: 0.9952 - val_loss: 0.0155 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9889 - loss: 0.0379 - val_accuracy: 0.9952 - val_loss: 0.0155 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45s\u001b[0m 49ms/step - accuracy: 0.9688 - loss: 0.0689\n",
            "Epoch 22: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0689 - val_accuracy: 0.9953 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0689 - val_accuracy: 0.9953 - val_loss: 0.0155 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9908 - loss: 0.0314\n",
            "Epoch 23: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9908 - loss: 0.0310 - val_accuracy: 0.9952 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9908 - loss: 0.0310 - val_accuracy: 0.9952 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 24: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9951 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.01347\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9951 - val_loss: 0.0161 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9920 - loss: 0.0272\n",
            "Epoch 25: val_loss improved from 0.01347 to 0.01155, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n",
            "\n",
            "Epoch 25: val_loss improved from 0.01347 to 0.01155, saving model to /content/drive/MyDrive/mnist_models\\mnist_cnn_best.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9919 - loss: 0.0276 - val_accuracy: 0.9963 - val_loss: 0.0115 - learning_rate: 2.5000e-04\n",
            "Epoch 26/30\n",
            "Epoch 26/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 0.9844 - loss: 0.0186\n",
            "Epoch 26: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0186 - val_accuracy: 0.9964 - val_loss: 0.0116 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0186 - val_accuracy: 0.9964 - val_loss: 0.0116 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9920 - loss: 0.0261\n",
            "Epoch 27: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 57ms/step - accuracy: 0.9921 - loss: 0.0259 - val_accuracy: 0.9956 - val_loss: 0.0126 - learning_rate: 2.5000e-04\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 57ms/step - accuracy: 0.9921 - loss: 0.0259 - val_accuracy: 0.9956 - val_loss: 0.0126 - learning_rate: 2.5000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m49s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 28: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9954 - val_loss: 0.0126 - learning_rate: 2.5000e-04\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9954 - val_loss: 0.0126 - learning_rate: 2.5000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m936/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9926 - loss: 0.0264\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9922 - loss: 0.0279 - val_accuracy: 0.9964 - val_loss: 0.0116 - learning_rate: 2.5000e-04\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 51ms/step - accuracy: 0.9922 - loss: 0.0279 - val_accuracy: 0.9964 - val_loss: 0.0116 - learning_rate: 2.5000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m  1/937\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 0.9844 - loss: 0.1197\n",
            "Epoch 30: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.1197 - val_accuracy: 0.9964 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.01155\n",
            "\u001b[1m937/937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.1197 - val_accuracy: 0.9964 - val_loss: 0.0117 - learning_rate: 1.2500e-04\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=15,\n",
        "width_shift_range=0.1,\n",
        "height_shift_range=0.1,\n",
        "zoom_range=0.15,\n",
        "shear_range=0.1\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "\n",
        "train_gen = datagen.flow(x_train, y_train_cat, batch_size=batch_size)\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "\n",
        "history = model.fit(\n",
        "train_gen,\n",
        "steps_per_epoch=steps_per_epoch,\n",
        "epochs=epochs,\n",
        "validation_data=(x_test, y_test_cat),\n",
        "callbacks=callbacks,\n",
        "verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "ZUygRIyn2YLK",
        "outputId": "600e431e-430f-40ad-9499-4f3bb4ee35fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.0115 Test acc: 0.9963\n",
            "Saved model to /content/drive/MyDrive/mnist_models\\mnist_cnn.keras\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGdCAYAAADNHANuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAW5FJREFUeJzt3Qd4k2XXB/B/WzroBgothULZZZaNgCAKAg4ERAX1VUDF14ELfVV8FRyf4hYVBLfiANQXcCEqe2+QXTZllbaMtnSPfNe5nyS0pSNJM540/991hSZtaJ+maZ+Tc59zbi+DwWAAERERkYt5u/oAiIiIiASDEiIiItIFBiVERESkCwxKiIiISBcYlBAREZEuMCghIiIiXWBQQkRERLrAoISIiIh0oQbcQFFREU6dOoWQkBB4eXm5+nCIiIjIAjKfNSMjA9HR0fD29q4eQYkEJDExMa4+DCIiIrLB8ePH0bBhw+oRlEiGxPRNhYaGuvpwiIiIyALp6ekqqWA6j1eLoMS0ZCMBCYMSIiIi92Jp6QULXYmIiEgXGJQQERGRLjAoISIiIl1wi5oSIiKqfgoLC5Gfn+/qw6Aq8PHxQY0aNew2roNBCREROd3Fixdx4sQJNceC3FtgYCDq168PPz+/Kn8uBiVEROT0DIkEJHIyq1u3LodiuimDwYC8vDykpKTgyJEjaNGihUUD0irCoISIiJxKlmzkhCYBSc2aNV19OFQF8vPz9fXFsWPHVIASEBBQlU/HQlciInINZkiqB+8qZkdKfC67fSYiIiKiKmBQQkRERLrAoISIiMjJYmNjMXXqVLt8ruXLl6ulsAsXLsDdsdCViIjIAv369UPHjh3tEkxs2rQJQUFBdjmu6sSjg5IvVh/BkdRM3N2zMVpEWraDIRERUVmko0janWWYWGWk84gu59HLN7/uOIVv1h/D4dRMVx8KEZFHn8yz8gpccrF0eNuYMWOwYsUKvP/++2qpRC5fffWVevvHH3+gS5cu8Pf3x+rVq3Ho0CEMHToUkZGRCA4ORrdu3bB48eIKl2/k83z22WcYPny4mt8iMz9++eUXmx/T//3vf2jbtq06Jvla77zzTomPf/TRR+prSAuvHOctt9xi/thPP/2E9u3bq3bfOnXqYMCAAcjMdM550qMzJSEBvuptRk6Bqw+FiMhjZecXos2kP13ytfe8PAiBfpWfCiUY2b9/P9q1a4eXX35ZvW/37t3q7bPPPou3334bTZs2Ra1atXD8+HFcf/31ePXVV1VQMGvWLAwZMgQJCQlo1KhRuV/jpZdewptvvom33noLH374Ie688041/6N27dpWfU9btmzBbbfdhhdffBEjR47E2rVr8dBDD6kAQ4KrzZs349FHH8U333yDXr164dy5c1i1apX6v6dPn8btt9+ujkMCpIyMDPUxZ03e9fCgRPv2M3K49wIREZUvLCxMjVGXLEZUVJR63759+9RbCVKuvfZa830liIiPjzfffuWVVzB//nyV+Rg/fny5X2PMmDEqIBCvvfYaPvjgA2zcuBGDBw+26ljfffdd9O/fHy+88IK63bJlS+zZs0cFO/I1EhMTVT3LjTfeiJCQEDRu3BidOnUyByUFBQW4+eab1fuFZE2cxaODklBzUMJMCRGRq9T09VEZC1d97arq2rXrZfv6SJbi999/N5/ks7OzVTBQkQ4dOpivS9AQGhqK5ORkq49n7969avmouN69e6vlIql5kQBKAg7J7EjAIxfTspEEUxLQSCAyaNAgDBw4UC3tSAbIGTy6puTS8g0zJUREriL1FLKE4oqLPabKlu6ieeqpp1RmRLIdsvSxfft2dZKXMewV8fX1vexxKSoqgr1JdmTr1q2YPXu22khv0qRJKhiRlmLZ9ffvv/9WdTJt2rRRy0itWrVSe9s4g0cHJcyUEBGRpWT5RjINlVmzZo1aJpHsgwQjstxz9OhROEvr1q3VMZQ+JlnGkaBDSIeQFLBK7ciOHTvU8S1dutQcDElmRWpctm3bpr5vCbKcwaOXb1joSkRElpIulg0bNqgTuHTVlJfFkK6WefPmqeJWOcFLbYcjMh7lefLJJ1XHj9SySKHrunXrMG3aNNVxI3777TccPnwYffv2VcsyCxcuVMcnGRH5/pYsWaKWberVq6duyy7AEug4g0dnSkyFrulcviEiokrIsoxkGmRZQ+aMlFcjIoWmcrKXzhYJTKQ2o3Pnzk47zs6dO+OHH37AnDlzVLeQLM9IMa5kb0R4eLgKmq655hoVbMycOVMt5UgLsdSxrFy5UnUPSWbl+eefV+3E1113nVOO3cvgrD6fKkhPT1eVz2lpaeoBs5e/95zBuFmbER8Tjp8f7m23z0tEROXLyclRNQpNmjSp8lb3pO+fp7Xnb2ZKWOhKRESkCwxKWFNCREQ69sADD6galrIu8rHqxKMLXUPZEkxERDr38ssvq3qWstizpEEPPDooMWVKcvKLkF9YBF8fj04cERGRDtWrV09dPIFHn4WD/S/FZFzCISIici2PDkpq+Hgj0E8bJMMlHCIiItfy6KBEsNiViIhIHzw+KDEVu3KAGhERkWt5fFDCTAkREZE+MCjh/jdEROTE/XOmTp1q0X29vLywYMECeBIGJab9b7K5fENERORKDEqYKSEiItIFjw9KQrn/DRGRa8m+sHmZrrlYsSftJ598gujoaBQVFZV4/9ChQ3HPPffg0KFD6npkZKQaAd+tWzcsXrzYbg/Tzp071c6+NWvWRJ06dXD//ffj4sWL5o8vX74c3bt3R1BQkNoJuHfv3jh27Jj62D///IOrr74aISEhagpsly5dsHnzZuiNR090FSx0JSJysfws4LVo13zt504BfkEW3fXWW2/FI488gmXLlqF///7qfefOncOiRYuwcOFCFSBcf/31ePXVV+Hv749Zs2ZhyJAhSEhIQKNGjap0mJmZmRg0aBB69uyJTZs2ITk5Gffddx/Gjx+Pr776CgUFBRg2bBjGjRuH2bNnIy8vDxs3blR1KeLOO+9Ep06dMGPGDPj4+GD79u3w9dVWCtw+UzJ9+nRVrCNbFPfo0UN945aYM2eOeoDkgdPd8k0uMyVERFS+WrVq4brrrsP3339vft9PP/2EiIgIlYWIj4/Hv//9b7Rr1w4tWrTAK6+8gmbNmuGXX36p8tf+/vvvkZOTowId+fySMZk2bRq++eYbnDlzBunp6UhLS8ONN96ovmbr1q0xevRoczCUmJiIAQMGIC4uTh2bBFhyvG6fKZk7dy4mTJiAmTNnqoBEqoglepNIsKLZ/EePHlUbCvXp0wd6wkwJEZGL+QZqGQtXfW0rSMZBshEfffSRyoZ89913GDVqFLy9vVWm5MUXX8Tvv/+O06dPq+xFdna2Cgiqau/evSqIkKUZE1mekaUkOf/27dsXY8aMUefja6+9VgUgt912G+rXr6/uK+dtyaxIECMfk6BEghe3z5S8++676gcyduxYtGnTRgUngYGB+OKLL8r9P4WFheoH+dJLL6Fp06bQE1OmJJ1BCRGRa8gSgyyhuOJiXN6wlCzHGAwGFXgcP34cq1atUuc3IS+858+fj9dee029X5ZI2rdvr5ZSnOHLL7/EunXr0KtXL5VAaNmyJdavX68+JsHS7t27ccMNN2Dp0qXq/C3H6tZBiTywW7ZsUVGW+RN4e6vb8kBUtO2yZFHuvfdei75Obm6uSkUVvzg+U8LlGyIiqpiULdx8880qQyK1G61atULnzp3Vx9asWaOyFcOHD1fBSFRUlFolsIfWrVurYlWpLTGRryfnYDkGE6kbmThxItauXauWeYovNUmQ8sQTT+Cvv/5S34MEMW4dlKSmpqqsh1QWFye3k5KSyvw/q1evxueff45PP/3U4q8zZcoUhIWFmS8xMTFwFC7fEBGRNSQzIpkSWSEwZUmE1GrMmzdPZUgkgLjjjjsu69SpytcMCAhQdSK7du1SxbZSdHvXXXepc/CRI0dUMCIJAum4kcDjwIEDKpiRJSQpiJXuHPmYBDNSLCsf86iW4IyMDPWASUAihUCWkgdWCnZMF0mROXrvG2ZKiIjIElJkWrt2bVXLIYFH8fIGKYaV5RNZ5pH6DlMWpaoCAwPx559/qm4faTW+5ZZbVAeQFLuaPr5v3z6MGDFCZUSkXfjhhx9WhbfSbXP27Fncfffd6mNSayIFu1JS4daFrhJYyDcnlb7FyW1JU5UmPduSupIfjokpaqxRo4b6gZZVaCPFQ3JxBlNQkpNfhPzCIvj6ePzoFiIiqoAsmZw6dXlhrnSlSr1GcRIYFGfNco6h1AwVWRIq/flNJFtSXo2In5+fWmpyB1adgeUbk4ErS5YsKRFkyG3pnS5NWo9k2IukskyXm266SbVOyXVHLstYKti4fCO4hENERORGLcHSViRrWl27dlWT46QlWApvpBtHSHqoQYMGqi5E1r+k0KY4mTInSr/fVXy8vRDk54PMvEK1/03tID9XHxIREVVzUigrSytlady4seqU8URWByUjR45ESkoKJk2apIpbO3bsqKbZmYpfpR9bUlvuRNqCJShhpoSIiJxBVg1k1ldZfHU4aVXXY+alilcuZZHq3orIOFy9kQ6cpHQWuxIRkXPIHjRyoZLcK6Xh4LZgDlAjInKe0oWc5J7s+XNkUFJ8/xtmSoiIHE66OIWzJp2SY2VlZdlt2cnjdwkWHKBGROQ8MhJC5mpIfaKcyNytDpEuZUgkIJEdi6WJxRRsVgWDkhKZEgYlRESOJrvFy0ZxMoVUJoySewsPDy9zVpktGJSoAWrc/4aIyJlk7pWMZecSjnvz9fW1S4bEhEEJl2+IiFxClm1knhWRCRfyJFNS07h8k8tMCRERkaswKGGmhIiISBcYlEhQ4q9lSjinhIiIyHUYlBTPlGRz+YaIiMhVGJQUawlmpoSIiMh1GJSUqClhpoSIiMhVGJSoOSVapiS3oAh5BUWuPhwiIiKPxKAEQLAxUyKYLSEiInINBiWyOZS3F4L8tIl0bAsmIiJyDQYlRtz/hoiIyLUYlBix2JWIiMi1GJSUGjXPtmAiIiLXYFBixEwJERGRazEoMWJNCRERkWsxKCmVKUlnpoSIiMglGJQYcadgIiIi12JQUmqqK2tKiIiIXINBiREzJURERK7FoMSIQQkREZFrMSgxCvHn8g0REZErMSgxYqaEiIjItRiUlJpTwomuRERErsGgxIgTXYmIiFyLQUmpvW9yC4qQV1Dk6sMhIiLyOAxKjIL9tUyJYLaEiIjI+RiUGPl4e5kDExa7EhEROR+DkmK4/w0REZHrMCgphm3BRERErsOgpIy2YNaUEBEROR+DkjKXb5gpISIicjYGJWVmShiUEBERORuDkmI4QI2IiMh1GJQUw0JXIiIi12FQUkwoC12JiIhchkFJMcyUEBERuQ6DkjIzJQxKiIiInI1BSTEsdCUiInIdBiXFsCWYiIjIdRiUFMO9b4iIiFyHQUkxnOhKRETkOgxKyli+ySsoQm5BoasPh4iIyKMwKCkm2F/LlAjWlRARETkXg5JifLy9zIEJgxIiIiLnYlBSCtuCiYiIXINBSSmc6kpEROQaDErKnVXCTAkREZEzMSgpJZRtwURERC7BoKQUTnUlIiJyDQYlpbDQlYiIyDUYlJTCTAkREZFrMCgpb9R8NjMlREREzsSgpJxCV2ZKiIiInItBSXnLN7nMlBARETkTg5JSODyNiIjINRiUlMJCVyIiItdgUFIKW4KJiIhcg0FJed03zJQQERE5FYOScpZv8gqKkFtQ6OrDISIi8hgMSkoJ8a8BLy/tOutKiIiInIdBSSne3l4I9mMHDhERkVsEJdOnT0dsbCwCAgLQo0cPbNy4sdz7zps3D127dkV4eDiCgoLQsWNHfPPNN9AzFrsSERG5QVAyd+5cTJgwAZMnT8bWrVsRHx+PQYMGITk5ucz7165dG//973+xbt067NixA2PHjlWXP//8E3qvK0nPZqaEiIhIt0HJu+++i3HjxqnAok2bNpg5cyYCAwPxxRdflHn/fv36Yfjw4WjdujWaNWuGxx57DB06dMDq1auhV8yUEBER6TwoycvLw5YtWzBgwIBLn8DbW92WTEhlDAYDlixZgoSEBPTt2xd6xamuREREzqedfS2UmpqKwsJCREZGlni/3N63b1+5/y8tLQ0NGjRAbm4ufHx88NFHH+Haa68t9/5yP7mYpKenwyXLN8yUEBER6TMosVVISAi2b9+OixcvqkyJ1KQ0bdpULe2UZcqUKXjppZfgKsyUEBER6TwoiYiIUJmOM2fOlHi/3I6Kiir3/8kST/PmzdV16b7Zu3evCjzKC0omTpyoApfimZKYmBg4C/e/ISIi0nlNiZ+fH7p06aKyHSZFRUXqds+ePS3+PPJ/ii/PlObv74/Q0NASF2dioSsREZEbLN9IBmP06NFq9kj37t0xdepUZGZmqm4ccffdd6v6EcmECHkr95XOGwlEFi5cqOaUzJgxA3oVyuUbIiIi/QclI0eOREpKCiZNmoSkpCS1HLNo0SJz8WtiYqJarjGRgOWhhx7CiRMnULNmTcTFxeHbb79Vn0evzMs3ucyUEBEROYuXQfp0dU5qSsLCwlQXjzOWcpbuO4N7vtqMDg3D8Mv4Kx3+9YiIiKoja8/f3PumDCx0JSIicj4GJWVgoSsREZHzMSgpA/e+ISIicj4GJRVkSvIKi5CTX+jqwyEiIvIIDErKEOxXA15e2nXWlRARETkHg5IyeHt7qcBEsK6EiIjIORiUlIP73xARETkXg5JysC2YiIjIuRiUlINtwURERM7FoKQcXL4hIiJyLgYl5QitaZxVwkwJERGRUzAoKQczJURERM7FoKQcLHQlIiJyLgYl5WChKxERkXMxKKls/xsGJURERE7BoKQcoawpISIicioGJeVgoSsREZFzMSiptNCVyzdERETOwKCkHMyUEBEROReDknKwJZiIiMi5GJRUkinJKyxCTn6hqw+HiIio2mNQUo5gvxrw8tKuM1tCRETkeAxKyuHt7YVgfw5QIyIichYGJRUIZV0JERGR0zAoqQA7cIiIiJyHQUkFuP8NERGR8zAoqQD3vyEiInIeBiUV4PINERGR8zAosSAoSWdQQkRE5HAMSirA/W+IiIich0FJBbh8Q0RE5DwMSirATAkREZHzMCipQCgzJURERE7DoKQCnOhKRETkPAxKKsDhaURERM7DoMSimhJmSoiIiByNQUkF2H1DRETkPAxKLAhK8gqLkJNf6OrDISIiqtYYlFQgyK8GvLy069z/hoiIyLEYlFTA29sLwf5cwiEiInIGBiWVYFswERGRczAoqQTbgomIiJyDQUkl2IFDRETkHAxKKsH9b4iIiJyDQUklmCkhIiJyDgYlFha6pjMoISIicigGJZVgoSsREZFzMCipBPe/ISIicg4GJZVgpoSIiMg5GJRYGJSkZzNTQkRE5EgMSiyd6JrLTAkREZEjMSipBFuCiYiInINBSSVY6EpEROQcDEqsKHQ1GAyuPhwiIqJqi0GJhUFJfqEBuQVFrj4cIiKiaotBSSWC/GrAy0u7ns62YCIiIodhUFIJb28vBPuz2JWIiMjRGJRY0xbMoISIiMhhGJRYgFNdiYiIHI9BiQWYKSEiInI8BiUWYKaEiIjI8RiUWID73xARETkegxKrproyU0JEROQoDEqsyZSwpoSIiMhhGJRYgPvfEBEROR6DEguw0JWIiMjxGJRYFZQwU0JERKSroGT69OmIjY1FQEAAevTogY0bN5Z7308//RR9+vRBrVq11GXAgAEV3l/Xc0pymSkhIiLSTVAyd+5cTJgwAZMnT8bWrVsRHx+PQYMGITk5ucz7L1++HLfffjuWLVuGdevWISYmBgMHDsTJkyfhLkJrMlNCRETkaF4Gg8FgzX+QzEi3bt0wbdo0dbuoqEgFGo888gieffbZSv9/YWGhypjI/7/77rst+prp6ekICwtDWloaQkND4Wz7z2Rg4HsrUTvID1tfuNbpX5+IiMgdWXv+tipTkpeXhy1btqglGPMn8PZWtyULYomsrCzk5+ejdu3a5d4nNzdXfSPFL3opdLUyhiMiIiILWRWUpKamqkxHZGRkiffL7aSkJIs+xzPPPIPo6OgSgU1pU6ZMUZGV6SKZGD20BOcXGpBbUOTSYyEiIqqunNp98/rrr2POnDmYP3++KpItz8SJE1Wqx3Q5fvw4XCnIzwfeXtr1dLYFExEROYS2LmGhiIgI+Pj44MyZMyXeL7ejoqIq/L9vv/22CkoWL16MDh06VHhff39/ddELLy8vBPvXUBNdZf+beiGuPiIiIiIPz5T4+fmhS5cuWLJkifl9Uugqt3v27Fnu/3vzzTfxyiuvYNGiRejatSvcEfe/ISIi0lGmREg78OjRo1Vw0b17d0ydOhWZmZkYO3as+rh01DRo0EDVhYg33ngDkyZNwvfff69mm5hqT4KDg9XFXXCAGhERkc6CkpEjRyIlJUUFGhJgdOzYUWVATMWviYmJqiPHZMaMGapr55ZbbinxeWTOyYsvvgi3G6DGoISIiEgfQYkYP368upQ3LK24o0ePojrg/jdERESOxb1vLMTlGyIiIsdiUGIhFroSERE5FoMSK/e/kbZgIiIisj8GJVZnShiUEBEROQKDEgux0JWIiMixGJRYiJkSIiIix2JQYm2mJJeZEiIiIkdgUGKhUGNQInvfEBERkf0xKLEQW4KJiIgci0GJDcPTDAaDqw+HiIio2mFQYmWmpKDIgJz8IlcfDhERUbXDoMRCQX4+8PbSrnMJh4iIyP4YlFjIy8sLwf6c6kpEROQoDEqswGJXIiIix2FQYoXQmhygRkRE5CgMSmzswCEiIiL7YlBiwwA1Lt8QERHZH4MSK3D/GyIiIsdhUGLD8k06MyVERER2x6DECqwpISIichwGJTYs3zBTQkREZH8MSqzATAkREZHjMCixAoenEREROQ6DEiswU0JEROQ4DEpsmlPCoISIiMjeGJRYIZTLN0RERA7DoMTG4WkGg8HVh0NERFStMCixoaakoMiAnPwiVx8OERFRtcKgxAqBfj7w8fZS17mEQ0REZF8MSqzg5eWFYH/TqHkWuxIREdkTgxIrcf8bIiIix2BQYiXuFExEROQYDEpsHqDGTAkREZE9MSixEgeoEREROQaDEitx/xsiIiLHYFBiJe5/41qFRQZ1ISKi6odBiZUYlLiOTNH912cb0Pv1pUjLZqaKiKi6YVBi4/43bAl2vkMpF7Hu8Fkkpedg9YFUVx8OERHZGYMSK7El2HUW7002X19ziEEJEVF1w6DESmwJdp0le8+Yr687dNalx0JERPbHoMRKrClxjXOZedhy7Ly67uUFHEnNxKkL2a4+LCIisiMGJVbi8o1rLNuXDGm6aV0/FB0ahqv3rWW2hIioWmFQYuPwNBa6OteSfdrSzbWt66F3szrq+lrWlRARVSsMSqqQKZEWVXK83IJCrEhIUdf7t45Er2YR6vrag2f5MyAiqkYYlNhYUyIDvLLzC119OB5hw+FzyMwrRN0Qf7RvEIYujWvBz8dbtQZLbQkREVUPDEqsFOjnAx9vL3WddSXOsdjYdTOgdT14e3uhpp8POjdmXQkRUXXDoMRKXl5eCPZnW7CzyPLMEuN8kv5xkeb3m5dwWFdCRFRtMCipwhJOOjMlDrcvKQMnL2QjwNcbvZtrgYjo3byOeV5JEffCISKqFhiU2IBtwc6zeI+2dHNl8wi1bGMibcFBfj44n5WPvUnpLjxCIiKyFwYlVWgL5vKN4y3eZ1y6aX1p6Ub4+nije5Pa6jqnuxIRVQ8MSmzATIlzJGfk4J/jF9T1/nH1Lvv4pboSBiVERNUBgxIXZUo+WXkI3V5djN2n0ux4ZNXLUmOBa3zDMNQLDbjs4z2NQ9Q2HD6L/MIipx8fERHZF4MSF+x/s/34Bbz+xz6kZOTix80n7Hx01W9X4AGllm5M2tQPRXigr5phsuMEgzsiInfHoMTJyzc5+YV46sd/1D4uYuUBbVIpXf44rT54aYprWWRmSc+mxpHzB9kaTETk7hiUVKUlONv65Zupiw/gYPJFRAT7qSFsh1MyceJ8lgOO0r2tOZiKnPwiRIcFoHX9kHLv18vYJsy6EiIi27z4y24889MOJCRlwNUYlFQhU2LtnJJtiedVLYl4bXh7dIzRppKuPsBX+eUu3bSJVAPrytPLWFeyJfG8yq4QEZF1Ayp//ecU5m4+jsw81zdvMCipUk1Jvk3LNsM6RmNg2yj0aaG9yucSTkkyDG2JcbR8eUs3Jk0jghAZ6o+8giJsOXbeSUdIRFQ9HD+XjbOZeWo/sbbRoa4+HAYlzip0fW/xfhxKyVSbyr14U1v1vr4t65ozJbLBH2l2nUpDckauGo52RVNtFkl5JIvSmyPniYhssu249mKuTXQo/GtcGlDpKgxKqlLommtZpmRr4nl8uvKwedkmPNBPXe/QIEy1F8sy0I4T2jwOurR0I0GbJb8kptbgNQdZV0JEZI1tidq5p1MjrZzA1RiUVGlOSYFFyzb/MS7bDO/UANe2ubQcUcPn0n4uq1hXctlo+cqWbkoXu0pgl84pu0REVtU6ik6NakEPGJTYILTmpZZgKRKqyHt/X1q2mTykzWUf79NCW8JZxboS5dSFbOw5nQ5vL+DqVtpjU5kG4TURWydQBX4bD59z+DESEVUHOfmF2H1K2zusk7HxwtUYlFShpkTqQLIr6PiQwstPVmnLNlOKLdsUZyp23Zp4gXvpAOYC186NaqFOsL/F/68nR84TEVlFJooXFBkQEeyPhrVqQg8YlNigpq+PmjFS0RKOadlGEik3d2qgWlvLElM7EE0iglSAw43lLtWTWLp0Y9K7uXGIGotdiYisriepaPSCMzEosYH88CprC37nrwQcTs1EPbVso3XblIetwZrM3AJzYHZtm8s34KuIabLrvqQMpF7MdcjxERFVJ9t0VuQqGJRUdaprGZmSLcfO4bPVR9T1KTe3R1igVoNSnr7muhLPfpUvdTV5hUVoXCcQzeoGW/V/ZaknLkqb/Lr+MDNOREQWF7nG6KPIVTAosVGIf9n732jLNju0ZZvODSxahriiWR3U8PbCsbNZOHY2E56q+AZ8tqQSexnrStgaTERUsTPpOTiVlqOaCjo0DINbByXTp09HbGwsAgIC0KNHD2zcuLHc++7evRsjRoxQ95cTzdSpU1Gd9795+09t2UamjE6+seJlG5Ng/xro3LiWR2dLpKZm2T5TPYl1SzelR86vY10JEZFFSzctI0MQ5K+dz9wyKJk7dy4mTJiAyZMnY+vWrYiPj8egQYOQnKydUErLyspC06ZN8frrryMqKgrVeafgzUfP4fM1li/bFNfXWFfiqa3B24+fV6OOJdjrFlvxFNfy9GhaWxUgHz2bhZMXsu1+jERE1W2SayedzCexOSh59913MW7cOIwdOxZt2rTBzJkzERgYiC+++KLM+3fr1g1vvfUWRo0aBX9/y1s83WeAmpYpyc4rxH9+0pZtRnRuiGvirOseMc0rWXvwLAoKi+BpTEs3V7eqB18fb5sDxfYNtDTk2oPMlhARuVORq7Dqr39eXh62bNmCAQMGXPoE3t7q9rp16+DJ+9+8/VcCjhiXbSaVMSStMu0ahCE80BcZuQX4xwNHzl+a4mrb0k3p1mC2VxMRlU1e+Jq2NunszkFJamoqCgsLERlZMgsgt5OSkux2ULm5uUhPTy9x0e/yTT42HT2HL4zLNq/f3AFhxomv1pBlhyuN49JX7PesV/mJZ7NwIPmiKvbt17JqQYm52PVQaqXTdomIPNG+pAzk5BepF9dNI6zrdPTI7pspU6YgLCzMfImJiYFeMyWym61pSNotXRri6jjbT6qXWoM9q65ksXGKq9SSWFOHU5YujWvBr4Y3zqTnqoJjIiIqadtxLUvSMSYc3sZBoG4ZlERERMDHxwdnzmgnERO5bc8i1okTJyItLc18OX78OPS6/82i3UmqsDIqNAAv3Gj9sk1xVxqLXf85fgFpWfkeF5RUdelGBPj6oIuxcIsj54mI9L8Jn81BiZ+fH7p06YIlS5aY31dUVKRu9+zZ024HJQWxoaGhJS56zZSYVgimjGhv07JNcdHhNdG8XrDaWM5TxqXLrr4bj2ib6BXfQbkqTK3BLHYlIrrcdp0Wudq0fCPtwJ9++im+/vpr7N27Fw8++CAyMzNVN464++67VaajeHHs9u3b1UWunzx5Ul0/ePAg3JmppkTcKss2rar+Kr/kyHnPOKGuSEhRG0JJMNa4TpBdPmcvY23OusNnUSQRHhERKecz88xL2x0b6i8osXpiysiRI5GSkoJJkyap4taOHTti0aJF5uLXxMRE1ZFjcurUKXTq1Ml8++2331aXq666CsuXL4e7alw7EDJ0VJZtnq/isk3pupIv1xzFyv0pqlBTL5skOXrpRqa42otMJwzy88GFrHzsOZ2uOpuIiAjYbuy6aRoRhFpBl+9c72o2jXEbP368upSldKAhk1yrYxdEbEQQ5j/UGw3Ca1Z52ab0ADA/H281/EtqVWQH4eoqv7DIPMV1gB3qSUxkzkn3JrWxLCFFtQYzKCEiKjmfpKMOl250233jLqRyuW6IfQfCBfrVQNdYrfhIsiV6CyJSMnJx4EyGXQpxNx89rzY0rB3kZ/eCq97GJRxPqc0hInL3Ilehn4H3VGK6q3SOSGvw6F6xDvkaeQVFOJ+Vp10y84tdl7f5xrd5OJeVjwvyNjOvxEj9mr4+eLR/C9x7ZRPVgmuLJcalG6nHkTkt9tTTWOwqRbQSTNk6JZaIqLooKjJgu7EduFOMPjMlDEp0SIpd31ikTSWV4MHWk355fth0HM/N36kKTG0h9RqZeYV4Y9E+zNt6Aq8Ma4crmmpBgKVkSe9SPYn9lm5MWkeFolagrwqwZHJhl8a27adDRFRdHE69qF5cBvh6Iy4qBHrEoESH2tQPRZ0gP7VBnaTaelh5wq+sBXfKH3tVQCLZifCavqrYSU7g4YF+qB3oh/AgX/W2llwP9FXLK+pjQX6qfkaSGvO2nsRrC/eqSayjPlmPmzs3wHPXt0ZEsGXLWYdSMlXNjNTP9GmpDY2zJxkIJNmShTuTsObgWQYlROTxthnrSTo0DEcNnWaPGZTokJxQZZDaz9tPYdWBVLsGJR+vOKSyB9KCu+ixPjY/MUd0aaiGnb31ZwK+35ioghTZv+bpwXG4vXujSpdjTEs3VzSrg2AHbZvds1mECkqkrkSWmoiIPNk2nS/dCH2GSmTeNdieI+eT0nLw+Wptj56nB7WqcqQs2ZNXh7fHvAd7oW10qCpafX7BLtw8Yy12nUyr8P8uMe4K7IilG5PexrqSrccuICe/0GFfh4jIHWzT8dA0EwYlOtXXOERtx8k0VXRqD+8v2a82YerauJbdpqeaqrh/frg3Jg9po7IeMib/pmmr8eIvu9VyUWny/Ww+pk1x7W/H+SSlSTu1zJHJKyxSnT5ERJ4qM7cACUnpuu68EQxKdKpeaIAqRJIRL6vtMC79YHIG5m7S9hCaeH2c3YeySdZlbO8mWPrkVRgSH61G5X+19ij6v7MCv/xzqsSsmmUJyerjreuHqjkvjiLfY6/mxpHzbA0mIg+240Sa+rsbHRaAyNAA6BWDEh0zjZy3xxLOm4sS1BNyYJtIhxZ9SjD14e2d8O29PdTEQJlr8ujsbbjr8404nHJR3cfUdXOtA5duTHo10x7DNW68OV9BYRHe/SsBt85cq4JLIiJrbTuu7/kkJgxK3KKuJLVKU3E3Hz2Hv/acUV0zTw9uBWeQQt0/Hu+DCde2VC3Nku0ZPHUV3v4zASv3pzp86ab05nw7T1wocylJ72RGzNivNuGDpQex6eh5jJu1BWnZ7vd9EJFrbXODehLBoETHZFS6nNBPp+XgkDHLYC0JZl7/Y5+6PrJbDJrXc15vun8NbcDa30/0Rb9WdVVtx7RlB3Ext0BNwm3vhPHvsvOy1JZIlmjjYa2OxV3sS0rHTdPWqKBUhtXVC/HHkdRMPDF3OzcaJCKrzgMMSqjKAnx90KOJttRiyi5Y6+89Z7D52Hk1LOex/i3hCrL775djumHGnZ1V4am4oX191frsDKbprmvcqK7k9x2nMXz6WiSey0JM7ZqY91AvfDGmG/xreGPpvmS8t3i/qw+RiNzEifPZSL2YC18fL7SN1vdeYAxKdE52Dba1rkRqEd78M0Fdv6d3E0SFua64SYpOr2tfH4ufvApfjOmKZ6+Lc9rX7m2sK5EJuXpXWGTAm4v24eHvtyI7v1DVFf3y8JWqKFg2Fnx9RHt1vw+XHsSiXaddfbhE5EbzSdrUD1UvdvWMQYnO9WmpnVDXHz6H3ALrZm38tOUEDiZfVFNZH+jXDHogLcPXxEU69RfjiqZatmlfUoZ6taBXssnhvV9vwkfLD6nb9/dtqjJMxbcXH96podpvSEz44R/sP8PCVyJy7034imNQonOtIkNU/YW8at5ixayN7LxCc4p//NXNERrgC09VJ9hfZRr0nC2R4GLo9NVYnpCiltreH9VRje0va8DdxOviVAFvVl4h7p+12S47NhNR9bXNTepJBIMSnZNlD1Nr8MoDltdEfLn2CM6k56o5IHf1bAxPZ+rC0eO8ElmGGT59jdoLSH5ePz3QC0M7Nij3/hKoTLujs7qv/J/H5m5Tyz5ERKVJhn3PKePQtBhmSsgFdSUyMXWGcQngqUEtVReMp7sUlOgnUyIdNDJ/5IFvt6pdl3s2rYNfxvdWtSOVkc0RP76ri8qqSHbl3b+12iEie5BuP7aeVw+7T6WrzkfZ5FWK5vWOQYkb6N08wvzksqQmYvqyg2p7almyGBpf/ituT2uvlk0Cj53NwonzWa4+HDUzZdyszWr+iKkQ+Zt7u6ulJktJ8PLGiA7q+vRlh/DHTha+UtUtT0jGgHdX4F+fbWDreTVbuvGy8yRvR2BQ4gakpkSqpsWaSkbOHz+XhVnrjqnr0uHirLZbvQsJ8EWHhmG6yJZI8fGw6WuwZF+ymkPzzq3xmDSkjU0bJMoyz33Gwtcnf/wHCUksfCXbyQyh5+btVNtb7DyZhl93nHL1IVEVbTftDOwGRa6CQYmb6NuyrkXzSt77e79K1fVuXse8qR+VbA1esd9+Oy9ba/GeMyogOZySifphAfjpgZ4Y0aVhlT6nBJ/y81aFr9+w8JVs99aifTiVlqOyiuKdv/Yjr6DI1YdFdui86Rij/yJXwaDETZgCDKkrKW/kvBQzzd9+Ul1/dnBrt0jVOdOgtlHq7V+7k5CcnuPUry0/sw+WHMB9szarV6PdY2vjl/FXokPDqv+hkAzLh7drha+yPPXoHBa+km3bUcxar2VZZ/6rCyKC/dXwvrmbtY08yf0kZ+SowWlyKjBlivWOQYmb6BJbSxU1JmfkIqGc2RRvLNqn0q6yS297N3kCOpM8Jl0b10J+oQHfGP/4OsuiXUl492+tRfvuno3x3bgealnOXqTw9ZO7tcJXyQS98xcLX8lyOfmFeOZ/O9Tfj1u7NMS1bSLxaP/m6mMSTGflFbj6EMkG2431JC3rhaglbHfAoMRNSAfNFU21DpJVZSzhrD2Yqk5GMkb4qYGuGSfvDu4x1l98tyFR/SF2VpZkxopLA9FeHtoOvjbUj1RGxkebCl9lAJuMqieyxLSlB3EoJVMFys/f0Ea9b1S3RqpbQ3b6/mrtUVcfIlVhkqs7zCcxYVDihrsGryzVGiwV8lOMm+7d2aOx2muGyjawTaRa5jiXmYcF27SlLkdbd/gsdpxIU/vW/LtvU4d+LSl8lcBHPPXjP2pTP6KKyLLvTGPQ/PJNbREWqL2iliJs2eVbzFx+iLVKbj3JNRzugkGJG9aVbDxyrsSr/N93nlaV8kF+Phh/jZZypfLrL8b0ilXXv1hzpNz6HHuaueKwentb1xirWn5t9fSgVriyeYSaAnz/rC24kJXn8K9J7kn2x5Jlm4IiAwa3jVL7UxV3U3wDxEWFID2nADNXaoELuc/PdseJNLfqvBEMStxI83rBqmMjt6AIm46eU++Tyvi3jfUD9/dtporTqGIju8eoAG7/mYtYXUmLtT1eha7cnwJpZhjXx7FZkpKFr51U6l0KFR+ZzcJXKpsE5vKCJjSgBl4e2vayj0sXzlMDW6nrX6454vQCcbKd/H2TjrwQ/xpoXjcY7oJBiZuOnF9lHDk/e2Oi6riQYOS+Plq9BFVM9gG6tWuMuv756iMO/VofG19dXt++PhrVCYSzyCZ+H/+rqyp8lefKW8bdoolMjqZmmouvpY6kXmjZu4j3b10PXRrXQk5+ET5YesDJR0m22nZcW7qJjwl3q3lVDErcta5kf4pqLZXKePHYgBYI8q/h4qNzH7KEI21yMqJdhpk5ggyy+81YbPrAVc7fpblNdCjevCVeXZeagd84CIuMZNly4rydKtCQGTe3dm1Y4YshWRIUczYex7GzmU48UvKETfiKY1DihiPn5WS6LykDr/6+F2cz89AkIgijummv/MkysRFB6B8XaU5LO4JkYWTZROo7LNnPxhFuio82F9c+v2AXWztJmbvpuCrAlkzalOEdKp1p1KNpHVzVsq6qPTFlV0jftrlhkatgUOJmZB5Fe+MJTpZuxH8GtXJIi2l1d6+xPfh/W0/YvRhUunvmbEp0WZakOHl+NK4TiAtZ+fhpywmXHgu53pn0HLy6cK+6LvUili4ryvNI/Lz9lHnXWdKntKx81eItOrrBzsDF8Uzmhkx1Jab1wuvaaZNKyTpXNK2tNi2UFPb3xgDPXr5Zd0x93rbRoSo97kpS+GoKwD5bpWVvyHOXbSRjJht2xjcMw9jeltehSbbvxg5ad46puJ70afsJbekmtk6geiHrThiUuKG+xroSMfG6OI6Tt5E8bqaT9ay1x5BfaJ89PrLzCvH1uqPmLIkefj63dGmI8EBf1Y0jY/bJMy3cmYS/95xBDW8vvHFLB/MeN5Z6cmAr9X+W7ks2dwCSnpduasHdMChxQ11ja6sakkf7tzBPeSXbDImvrzqXktJzsHCnfSag/rjluFq+kZZcvWSxAv1q4K4rGqvrn67S5qaQZ5Elysm/7FLXH+rXDHFR2s7j1pD6NZm3I95U21ow66ZH29y0yFUwKHFD8krl9REdzNMWqWrj+00n6y9WV32Ymgws+mSldtK/v09TtXSiF3f3jIWfjze2Jl7AlmN8letp/u/3vUi9mKfmHT1chSGLj/VvoaYTbzp6XnWvkb4YDAZsN42Xd7N6EqGfv5hELnLnFY3USO1/TqRhqzHtaauFu5LUrpyyjntLF311RMm+JsM7NVDXTYETeQYZISBFzrKS+MaI9ioYt1VUWIB5KvKbfyaobS5IP46kZiItO18FjnH1Q+BuGJSQx5Plm2Edo9X1L1YfrdIrFNkjRMgf7Zp+tv/hdxTTgL2/9pxRf7yo+svMLcBz83eq66N7xqJL49pV/pwP9muGkIAa2Hs6Hb9y/o0ul27aNwhzy65M9ztiIgfuHvzHrtM4cT7Lps8hI+v3nE5HTd9LS0J60yIyBNfE1VNb1H++2jnZEtmnSbZDINeQThnJ3slGlKa23qoKD/Qzz7+RuSX2KhIn+01ydcd6EsGghAhQRX/SuiuZ6Fnrjtn0OUw7rY7qHqPGvOuVaQ+eHzefUAW5jpSckYN+by3HkA9XMzBxAVmO/Gqtlv177eb2dp36LO3EkmWUbS5kGBvprci1FtwRgxIio3uMMxtkKJ2kvK2x80Qa1hw8q4qQTW3Gep7PIqld2djx2/W2BWCW+r/f9qrOpoQzGViw7SScbdm+ZI8dr59bUIhnftqhsmI3d26gJrLakwQ4jxgLZmW7C2mFJ9fKyitQ077dOVPi2ZulfDsCOLkV8PEFvGtcuhS/XebH5OID+PgBDbsCnf4F+LtfQRGVdHWreqrlUWotpChwtLGYz5qN94Z0qI+GtZy38Z4tZG7KuL5N8ejsbfh67VHc37cpAnx9HFJc+cs/lwKCGSsOYUSXhlbPxqjKhnP3zdqshsXVCfJHz2ae1T7/0bJDOJB8EXWC/PDCDW0c8jVu795ItZjL8pBkZKTWhFxn54k09XyPCg1A/bCacEeeHZRknweyq9gauesnYNkUoOsYoMcDQKhWMEnlyDoH7JgL5F4E5NzkJck6L+2tl+ltGe8TptsRrYDY3nY/NNlJc2zvWEz6ebfaD0fqQizZXVM2KDPNOPm3i0fKW+r6dlF4I7wmTl7IxvxtJ9XJxd51JC/8rM3EGNk1Bn/uSVLBntTs3NjBOb8jsqOtaXrty7/twW+PXOm0gMi0IWPKxVx0dkEaPSEpAx8tP6iuv3hTW4ctJ0rXmowmmPDDP5ix/CDu6N4IYYG+DvlaVLltplZgN82SCM8OSm79GsjLBIoKgKJ8oKgQKJS3cikACgsufUy9v7DYx/KB3HRg+2zg7AFgzfvAuulA+1uBnuOBqHau/u705/QOYO6dwAU7jHTv/m9g0Kta5sqORnRuiLf/TMDRs1lqauWANtqmfRWR0e1y7pP0uIytdwcyP0UCMJldIa90JXCw5/bm05cdVLUGkaH+eP7G1qgfHoCpiw9g+rJDuKF9fYdPuZUAyLRcFOjno7pEfth83O7BV3nOZ+Zh+Edr1FyQ78f1QK9ml7aGcDRp0Z04bwfyCw0Y0DrSPBreUYZ2bKDqqfafuagyhk8PjnPo16PqtwlfcZ4dlITbYY5E7yeAA38Caz8Ejq0B/pmtXZpeDfR6BGh2jfbq3tPt+BH45RGgIBsIbww07SdNtIChSL1Rb823TW/LeF9BDnBwMbDxY+DMLi2wDK5r13VyOXF9vPKw2uW3sqAk9WKuOtnpYeM9a43q3gjvLzmAwymZFgdgljiYnGEu+n1xSFuEBPiqFulPVx5WwcGyhGRcY9yh2VE+XHJABYr94+qhV/MIvPLbHhVs3tChPkIDHP9K/vU/9qmARLz0yx78/uiVThukN2/bSTUgL8jPB68Ma+vwAFCyT/8ZFIdxszbjizVH1M+6XmiAQ78mlT2SQH7u7lzkKjw7KLEHb2+g1XXa5eQWYO00YM8C4PAy7VKvrRactBsB1NBvR4bDSLZp8WRg3TTtdrP+wIjPgMAqzErYtxCYd78WBH5yFTDyW6BBZ7sd8t29YvHZ6iNqa3fZDbVNdPnZj1lrj6qCUdncTApI3Umwfw3c0aMRPl5xGJ+sOmyXoET+MD43f5d6lS4BwWDjmH1pIf3XFY1VsDdt6UFVv+Ook+XhlItYsF3Lkjw2oIXKXn234ZgKvuRrP3d9azjSxiPnMNcYqMpjLEW+UlA8xorN72yVnpOP1//QdgB+pH8Lp9UVDGhdD50bhauT4odLD+KVYcwUO9uptBykZOSqfY3aRWs7ybsjdt/YU4MuwK1fAo9uA3o8CPgGAcm7gQUPAO93AFZPBbK1SNYjZKYC3wy7FJD0eRK488eqBSQi7npg3FKgTgsg/STwxWBg+/ewF5nnYDqZyiu/8kiHztfG9mG9bLxnrbG9mqg/YnIi/ce4Hl0VP245oT6XzGp5aWjJV+nSlSQ1CHLi2nDEcWPu5aQoWRI5UXZoGK4GSJkKPaVWyJFD46Tt2TSo7PbuMZh4fZx5lsfZi7lwtPcXH1AZmqYRQeZuMmeQn7Np2Ua616TOilyzdNO6fqguBzdaikGJI9SKBa57HZiwG+g/GQiOAjJOaxmD99oCiybaVldRVATkZWnFoumngQLHzpioklPbgI+vAo6uAvyCgdu+AfpP0rqW7KFuS2DcEqDV9UBhLrDgQWDh01qtjx2Y2np/2X5Kvfooi8xmkHHO0rEzsK0+Nt6zZWT4TcZptlXdqE9mnkxZqL1Kf3xAi8u6kCSlf1vXhuaaE0c4lHIRP5uyJP0v7Q11dVw9VfMjGZxXf9eO0RE+WXkIB40dL88MjsOobo3QNjoU6TkFaoiZI+0/k2GeSTL5prYqAHQm2Ry0b8u6KCgy4L2/9zv1axPcehO+4rh840g1awF9JgA9HwZ2/U+rO0neA6z/CNjwMdDiWu2ELXUS6pIL5Gdrb023C4rdLiwVhATWAbrdp12C60E3tn0H/PaEFizUbgaM+h6o54Dit4AwYOR3wMo3geVT7FpnIh0THWPC1cZWknp/otTmhzLBUmpOTMPIHN7VoWpqDNpyoZ3dd2VTzNt6UnUQScdITG3bWppfW7gX57PyERcVYp6QW9q/+zbD7I3HsepAKnacuKAyGY6oJZECz/YNS6awn7+htZq6u3jvGaw+kIorW0TYvQVZsjTihRvbqCUr8dJNbXHLzHWYs0krtLX392xaNnvxl92q2+jaNpF2n0liqacHtVKt4D//c0o9BxzxvVL1LXIVDEqcoYY/0PEOIP524NASLTg5vBzYv6gKn9QLyDoLrHgDWP0e0OE24IqHgUjHzCOwiGQp/nwO2PiJdrvldcDNH2vBg6PISbrfs0BUB7vXmcgfVZnlIfUIMn+h+CwPGcgl7bQy0VIGU1VKAoqzh4CLSVo7dN5FrXtLrudmlHPbdD1DeytdX34hQM1w7TENML4t83YZH5NOJbULcrHiYRjQpo4Xrm1WE+sPncX3K/7BMzKK3Hw/4319Ayr8Oa47dNa84durw9uXu+eGBDxD46NVMaZkSz6+qyvsRTIUprkokqkpa8S+tHlLNkEKX+1ZfCpBgbRAS33Rlc0jMNSYfRJdY2urjRCl9VoCh58e6GXXTifxx64krD10VmVHJt3our8B7RqE4ab4aPVzGP/9Nvz6yJUIq8kWYUfLKyjCrlPpbrszcHEMSpxJ/mI3H6BdpD1WAhMZyCZ/8GvIxR+oUdP4NqDY+8v4mNj3m1avcWITsO1b7SLdPpKZkYJSZ9Y4ZJwBfhwDJK7VbvebCPR92iGv7CusM5lzh9aiLXUmQ6ZqwaCNrmsXhfphATidlqP+yN7WNcZ8ApLiUCFtteUOHpMW8uMbgH2/az+r87Zv9mcmAYpc0uw71vtT+UeeVv8YL2VpPQS46hkgqv1lk0P/u8BUR9EIXRpX/EfxoaubYf72k/hz9xkcOJOhggV7+HCpliWRTIGcHMsiwYoUwUrx6exNx+22R5E8PyT7I0HB/w1rd1l90bPXxeHP3UmqnkaCExkiZy8ySfX/fttjrm2yNdNlLy8PbavG2yeey8KTP2zHJ3d1tXsQVp6CwiLsNhanu+NmdLaSrjYJTGoF+qJxHX0Pb6wMgxJXqd9Bu1RF22Ha5fhGLTjZ+ytwaKl2qdtaC05kbooEN450fBPww11a3Yx/KHDzJ1o3krOZ6kzmPwAkLNTqTE5tt3meifxRu7tnLN5YtA9frD6CW7s0VCeb5ftT1Chnabn8V49SJzWp+ZFgUwKR/X9o2SwTH38gvBHgH6xNAJash7w135a3oWXflusyQViyKTkXtIJpeZuTVsb1tGL3ketpgMEOI8Dl+SWXVjcAVz0NRHdU75YATTpbIoL98MygypfpmtcLwaA2UVi0Owkzlh/CuyO1z2OvLMlj/S/PkpjIksoTA1pi8i+78e5fCbipQ3SVh32lZeWrzIt45OrmiI0Iuuw+kaEBeOSaFuq59PqifRjYNlK1StuDDEmTzgsp0H5QB23p8hjPuLMLRsxci8V7kzFz5SE81E8bR+9IsqR6/6zNWJaQguiwALU3z8juMU5pAXclg8GgugVNrcDuWHBfnJdBviOdS09PR1hYGNLS0hAa6h7DqVxCXomvnwls+0ZL/4ugukC3cUC3e4EgBwxw2vIVsPA/Wr2LTFod9R0QUf5JwSmkINhUZyIa97a5zuRCVh56TlmK7PxCfH9fDzXzYtQn67D+8DmM69ME/5Wujsyz2lKcBEIHl2h1QCaybNJyMBB3g5bFkgDD2eRX3LT8Y56QW2xirvH6/G2n8PS8nYgIDsCKp6+Bn2+NS9m25L3AyreAXfO0ZR3RcjBOxj+Cq2dnqFdp74/qqAZpWULqSW6atkbV4ix/ql+VX93LMpsEJZIl+fTurpW+mr7u/VVqBLt0qEwaUrXlDum2+X5DIprVDcLCx/rAv0bZmTPJKA2eukp1/8hof3u0JkuXy7XvrVSP/8x/dcbgdo4dlGYN6cKZOG8nJEny7X2OHSAnp7Fn/rcDP2w+UeL90pI9qlsMxl7ZRAVtjhpWJ91kMqxv09Fzqv5sSLzzJnt/ueYIXvp1j/pdmnP/FegWq6/RBNaevxmUVEfyCnnrLGDDTK1lVsiST/wo4IqHgLp22L5cim//eFoLSkyp/WEz9LUHkGmeiSx3hDawuc7k+QU78e36RNViOv6aFhg2fQ2a+iRjwYA0hB79W1uyUoPejMIaactJEog06mn3qbOOIie2Pm8uxZn0XLx9azxuKWuJIWU/sOptYOeP5u95eWE8VtQfi0kPjrHqVdpdn29QSx539mik6lCqMqxNTszyl0xGyZe3dFOcFGPe/cVG1Q696PG+aF7PtmBxy7FzGDFjnbo+9/4r0KNpnUo3CBz71aYqf12T+77epLIRUsfyzb3ddfUqWU4t//lph6o1kizab4/0Ud1ejiDdPjIIUAKgaXd0Rnp2vsoeSAZNyAlblmOlKD0+xj6FoLL0KLVRP287qTJVJr4+Xvj23h6VPhfsYdPRc7j9k/Wq40mKq/W4GSiDEipZeLrnZ21pR1p0TVoMBLrfb9ynx6vYq2XTH7Qy3lf8tixR/PqoVssi7+v/AnDlBH1OrpWTqKnORJZPTHUmkk2R7iDJ8EhrtVyXQEseM3Vd3qe9//S5NLw0fzv8vArQO+wsOlxcg9bepVq6pc5CljUkEJHrenwsLCDLKbLE0CoyBIse71P+Se7sISQueBnRib+ghpcxIJMpxlJz0rinRV9rw+GzGPnJevj5eGP1M1fbPAXUlCUZ2CYSn1SSJSnunq82qUm2V7eqiy/HdrdpueDGD1ar+hRpdX7zlniL/t+9X23Ckn3Jqn3267HdbA4kZDLu2C9NAU4ftSymN1LvcvOMtarmQWqN5JW8vWs9TBkZ8drw9mogoCmDsWJ/imp1lyJgk+6xtXFfnyaqQ8vaWpfkjBw1JkDqgqR2xSQkoIbaPkHGB8jPNjzQFwse6l3mUp69JKfn4IYPV6uvKZmZD0Z11FVQasKghC4nP+LEddrePFLrYEq/V5V0Y4z4AmgxALomNRWmOhMhxcWylFEFBi8feDXuBcTdqNXP1LJPwaSrydyVXlOWIDOvEF/f073c1lKpo+j/7nIEZh7HjEbL0Tbl90uPaWwfrSMq9soKv5b86bl15jpsPnbe5uUMebU6cKqWJZFumrZWTLKUmSaD3lupXmV+NbYb+rWqZ1MAVzvID0smXGXxpnfSOjxQllwKi9RSkyw5Wav4UpB5GVGn5PsdMm01MnIK7LJcVtzSfWcwbtYW1Qr9yDXN8eTAsrPAu0+lqT2qfv3nlPp5C5kvJB12t3RuWOGwsay8AlWkLMubqw+kqGJqIcGgPGek++6auHqq4F02opRAWwYRygC7+Q/1dsgGhfmFRbjj0/XYdPQ8WkYGq68jW2ToEYMSqpi0pcqyjgQnkgko3vqpmK7L29K3jW+FtOAOnwHUbgq3YKozkRbq4kstJt6+WmeTFJOqt75aZsX4vrR8L+xKysE5hOBM5FW4754Hqj6ZVqde/nWPmmQrSwJSC1AWeWUqr1DNdRQZJ7TWdOkAk00rTbU8UhDb5KpyM0em5QzZNG/ts9eYZ3tY6pHZ29SJZlDbSJvai6VAVebNyDLKH4/1sfhVvMxzufa9FcjJL8I7t8Zb3U3z5qJ9+Gj5ITSqHYi/nuhbfgdXBcWtby5KQN0Qfyx98iq7Fc06yl+7k3D/N1vU9Wl3dLLLTtEyQ0iWLqTeS5Ya37qlQ6WZgtNp2aolXGqAJEgS0rEiWyBIUbs8nkKCnDUHU1VGRAKSrLxLheIyTl9avG/oEK0C0rKyKcOnr1UjA3o2raOCe3sPsnvZ+Dsa4l8DP4/vjaZ1XVCrZiEGJUQVyT6vDaiT4MMcgPhVutwivyZDp69RKdsf/t2z0rZXdyYn3H5vL1d/mMvKPhSvo5B0vEzyNEszBidS02Qa9hfTA2h906X5KNIqLd1ARUUwFBVg9sZjOH8xGz0ah6Nro9Bi95FZKoWAl4+2hYMUCodElphgOsiYJVn4aJ8K9yiqKDN09dvL1TTaF4e0sWh/GnkujPlyk1oakJOO7AJsbdpctijo/84KJKXn4KmBLVWtkqWS0nJwzTvL1Yny3dvicXNn+7UXO3qTQtmoUbrWfh5/ZZXqaST7IstC8nOTbN5no7tatSwkj79spCkn9uPntMJ0WUYc1iladevI8Lfik5ylzVYCkWEdG1i0JLMvKR23zFiHi7kFagfu10e0t9vSys/bT+KxOdvV9U/u6qL7adIMSogcRJYsUjNz0UzHr0rsxZSBuLlTgxItu8XrKOTVqRTElin9FLDmfa0QWqYR20tkOy04aXYNHl9XEwt2ncXgtlGYeVcXmz+lTOx9fsEuNeRLOoEqW4aRwXkyGExOYn883sfm54Pp5CL7BC158ipEW9gdYqqhkcD4pwd66rKOoLyup399vkF1rrWoF4wFD9u25CA7c4+YsRbHzmahXYNQzL2/p81LFxJ4SyZE6k5MY9pNJIMiGZ3hnRugU0y41Y+z1PxI/ZAs98icGnvsIp6QlKEK7SU79FC/Zub9hvSMQQkRVZmpZVfWzVc9c7V5t1l5pSuveOUP9pIn+5WZvi4hI0mb8Hv+mNaCLHsfSeZDhuqptz4oUu3Ip3EuuxDdm0YgvlEd88fUW+meOrIKOK29OjTJNvhhQ1FrxF05DFGdrte6ymw4QcvJ8gZjoDW6Z2O8NLRdhbvwSoZDXkXLILbHB7S8tDwoA+1SEoCUvUDyPu3txRTjcmGpZVBDEQwwICM7H4VFRfD3AQLVEk6p+0kLubSVy5YVNcORUhCIX/dn4QKCMapPe0TXjy7xcfVWar0c0fEl2SsJMPNN22LkVLAlRll7UHmpx++tPxNUhqpz49rq8S7zZB8WA9SPv2zGktR3yJLNPyfSEFO7Jv73YC/UC7FPR49kAL9bn4hCg0EFI5KBqeqyy9drj6qZOPItzrizai3b6Tn5GDptjaojkqVVWRZy+PYWdsCghIjsYuTH69T8hX/3bYqJ17cuUUch6/e3Gifc2oOk0p/+aYda01/19NVl11jIrtMymO7QUlzYuQjhhcUG0wlp+252tTbNuGk/q2p+pH7gzs82qD/yix7rU+6U2Unzd2DJhq3oG56KV3r7oEbqfiBFApAEIF9HO+OqwXySwSnePYeyb5vPa6U+JoFF8cCjisXhVpNl1ehOQEx3tQRYEN0N4+YlquFoEhRLQKLnWgqTyT/vUruJB/h6q6VfW/YDKioy4N/fbsHfe86oeSsyvr/SFwQ6waCEiOxiyd4zuPfrzaqYbu3Ea9SygZwQejSprWpJ7LlsIDNS+r21TM17kDHtUnhYUQp78Psr0AIn8G2/DNQ7swY4tlZr5Tbz0mbSyFKPLPmYB8UZP1a8zd14XcbUbzuepuacyNRXL/k/UrQrxeEp+5B5YhcMKQkI9ipnOUqKpWVwYN047SKbUIY11LI9JVrsvUoMsXt/6QH88s9pNIkIxsy7uqKGj/H+8qdZhiDK3KHs81i7+xBW/rMf9XyzcWeHUPgXpJs/Zp7gKxN/nUEVhgeUsSWG8bbK1Jge72KnGOPpRopApS5Evk15vEMlVWS+T5EW5GWlXvZljxZFYjtaolPvwWjc8WptcrWztrKwkWTi7pu1GcsTUlAvxF8tW1m6VGci+0RJhkmWDH98oKfdZq04A4MSIrILeXUmmZFDKZno0yJCDTqTwVB/PFb1oV9l+WrNEbz46x40rFUTy57qV27h4sPfbcXvO0/j+vZR+OhOYy2JFC9LYGLaZkF243aQAtRAjXotSwYfcnKs3cSmZZPzmXm4+p3luJCVr3YUHt0r9rL7nL2Yqwpy03MKKg7aCgsubTMgU3wV45/44h125jflfcygfS9l7sEVoC2tVYGcdh7+fisW7kxS+0vJ0Ls6wVrni/nrnzusbaFxfD1S965C7czD8PYqdbryDwMadtWKqRv10Aqi7TnAUZbl8rMubZApb8u8nmnclyrr0nKd6fuQoLuwEEv2JCMtO091mPWPq6t+ly7Fa8Yr3j5alssvyLi9RBD2nTfgvRUnkWGoiTH92mJgx+bax9V9QnQ/nJFBCRHZzZyNiXjWOJhKVDQLwh6Dtq58YynOZuaV21UiXQ0yn0P8+XhftIoKKb/Q9tAyLUCRqcZlnXTLOCGfupCtWjoDanijZWQIvOWlfK1YbM6qh88SApDkH4vPH78VdcLsG5R9s/4YXliwC6EBNbD8P1dflpp/9n87MGfTcbSNDsUv4690i1qCymRIjcT0NWrfpIpqJOZuSsQz/9uJUGTivd756B90VAUqOLHl8iUzyT5FtDRuWlr656tulHhTZlAmy1UqyDAGG/aa6+TIZS4/LYDRsm+4/JhL3Lw8c2Um24QY97Ry1flbn9NWiEgXhnVqgLf/SkDqxTzVFvnw1Y7bWE0GWN3bp4mavyEzPKT9svTEzQ+WHFBvZXpmuQGJkGnFne7ULlYIycnHTW8vV9/v821a474+TXHifBbuenclsosK8eYNHewekIg7ujdSszNk8qk83jKZ1EQGcc3drO0KLZmU6hCQCJmtMvNfXVTx5uqDqZi6eP9lAa/MsXlu/i51/a6rO6B/8Q0fJSuUvBtI3KDtxi1ZlbRErcbH7rwubZJpzmIYL/7F3voGFcsimZYGL30OWZ6cvfG46vrpElsb/ePqlVxWLMw3B0OFORnYkJCIguwM1PXPR6taXvCWIMyUmTEtV0rrffY57VJVZRYoOxeDEiIqlxScPjM4Tu0r8tYt8VYP+bKWLEvIpFTZs+SvPWcwuN2lGQxywpZ0v/wNf7SCnYCreqKUE6MMh5PvWWZTTP55t2rB7N6kttop2hEk0JCA47aP16mhdBKkSK2FLKFN+mW3ekEr7dlddbbZWlVJNkpmeEhr9IdLD6JTo3BcExdpDsYe+m6rOoHL1NSnSmfofGpoHTpy6XG/9r60k9rmkaYBiaXriEpcLacIWDIP5kDDuJTiG2iXrSNkZFxc49Nq6QqHgP9rX/5S3PPzdmB2+nE1sv63h6+Ed61Sm1aaAhjz8lFZWZ1Sx1zmt1DsnZJlcjEu3xCRrrz9ZwKmLTuIDg3D8PPDvc0FtQ9+uwV/7ErCDR3qY/od1m+saCk5Cd744WoVBMkcjF0n0421NI7fX6b0DJIft5xQXUmy261MbrV1fyC9m/TzLsxad0zNipH6kiKDATd/tFYt5Uk90xdjutl9zxxXmrb0AN7+a78KRr8c003tg1TWkpWXF/D12O6XfdydWHv+rj4/ZSKqFsb2jlUDxXacSFPFtWLPqXQVkMgf6ccclCUxkRPFZOP+LBKQCBl85YwN72T/Hxm5v+XYeVVn8sYf2lKEfM/VNSAR/72hNTrGhKv5JQ98uwWjv9ioAhKpoZnxry7VKiARsgwq2R8JgKVwW6YTF58R9MLPu9V1yQ65c0Bii+r1kyYityddGLd3b2RuhSxdSyIpf0eT0fmy1b2IdXAtTXFRYQHmrzXp593qxCz7C5XVkVOd+NfwwUd3dlbzR2Qrh6Nns9Q8DskiSJaoupHs35Sb26sdizNyC9SO1TKp9lxmHh78dqtqkZddjB+0wxRYjwhKpk+fjtjYWAQEBKBHjx7YuHFjhff/8ccfERcXp+7fvn17LFxo3K2ViKgM4/o2UUsmMrxNMgaLdjsnS1LcK8PaYUyvWDXC3tG1NMXd16eJKio2efGmtnbf0E2PZHbHB7d3gtTxSh2FdONU5+yQBGIf39VFBb0nzmdj3KzNeGzONjXDRd73zm3xlxV6ewKrn+lz587FhAkTMHnyZGzduhXx8fEYNGgQkpOTy7z/2rVrcfvtt+Pee+/Ftm3bMGzYMHXZtUurqCYiKk3G2o8wtgRLq6yQ0d/lTVp1hIhgfxUQxEWFOv1k9fLQdmoZaVjHaPRp4Tnpe/leZfuCZU/2c8gsHL2RfZY+H9NNtYLL3jurDqSqpUsJhKW+xhNZXegqmZFu3bph2rRp6nZRURFiYmLwyCOP4Nlnn73s/iNHjkRmZiZ+++038/uuuOIKdOzYETNnzrToa7LQlcjzyB4f/d9ZrjY0kyzJ30/I0DbnBSWuJkPVQmv6VpsWYCrf2kOpuPvzjSgoMuD9UR0xtGMDVBcOLXTNy8vDli1bMGDAgEufwNtb3V63TtvKvDR5f/H7C8mslHd/kZubq76R4hci8ixNIoJwQwdpogSGdIj2qIDE9CqaAYln6NUsQo2f//beHtUqILGFVRVEqampKCwsRGSk1kduIrf37St7YE1SUlKZ95f3l2fKlCl46aWXrDk0IqqGZKS6dGXc4qD5IER6IXNpSKfdNxMnTlSpHtPl+HFtmiEReRZZV7/3yiYeu75O5GmsypRERETAx8cHZ86cKfF+uR0VdWnyYnHyfmvuL/z9/dWFiIiIPIdVmRI/Pz906dIFS5YsMb9PCl3lds+ePcv8P/L+4vcXf//9d7n3JyIiIs9k9VQaaQcePXo0unbtiu7du2Pq1Kmqu2bs2LHq43fffTcaNGig6kLEY489hquuugrvvPMObrjhBsyZMwebN2/GJ598Yv/vhoiIiDwnKJEW35SUFEyaNEkVq0pr76JFi8zFrImJiaojx6RXr174/vvv8fzzz+O5555DixYtsGDBArRr186+3wkRERG5NW7IR0RERA7BDfmIiIjILTEoISIiIl1gUEJERES6wKCEiIiIdIFBCREREekCgxIiIiLSBQYlREREpAsMSoiIiMg9J7q6gmm+mwxhISIiIvdgOm9bOqfVLYKSjIwM9TYmJsbVh0JEREQ2nMdlsmu1GDMvOxGfOnUKISEh8PLysmsEJ4HO8ePHOb7eCnzcbMPHzXp8zGzDx802fNzs/7hJiCEBSXR0dIl98dw6UyLfSMOGDR32+eVB5BPQenzcbMPHzXp8zGzDx802fNzs+7hZkiExYaErERER6QKDEiIiItIFjw5K/P39MXnyZPWWLMfHzTZ83KzHx8w2fNxsw8fN9Y+bWxS6EhERUfXn0ZkSIiIi0g8GJURERKQLDEqIiIhIFxiUEBERkS54dFAyffp0xMbGIiAgAD169MDGjRtdfUi69uKLL6qJusUvcXFxrj4s3Vm5ciWGDBmiJhjKY7RgwYISH5fa8kmTJqF+/fqoWbMmBgwYgAMHDsCTVfaYjRkz5rLn3uDBg+HJpkyZgm7duqlJ1/Xq1cOwYcOQkJBQ4j45OTl4+OGHUadOHQQHB2PEiBE4c+YMPJklj1u/fv0ue7498MAD8GQzZsxAhw4dzAPSevbsiT/++MPuzzWPDUrmzp2LCRMmqDamrVu3Ij4+HoMGDUJycrKrD03X2rZti9OnT5svq1evdvUh6U5mZqZ6PknQW5Y333wTH3zwAWbOnIkNGzYgKChIPffkl9pTVfaYCQlCij/3Zs+eDU+2YsUKdRJYv349/v77b+Tn52PgwIHqsTR54okn8Ouvv+LHH39U95ftOm6++WZ4MkseNzFu3LgSzzf5vfVkDRs2xOuvv44tW7Zg8+bNuOaaazB06FDs3r3bvs81g4fq3r274eGHHzbfLiwsNERHRxumTJni0uPSs8mTJxvi4+NdfRhuRX7F5s+fb75dVFRkiIqKMrz11lvm9124cMHg7+9vmD17touOUt+PmRg9erRh6NChLjsmd5CcnKweuxUrVpifV76+voYff/zRfJ+9e/eq+6xbt86FR6rvx01cddVVhscee8ylx+UOatWqZfjss8/s+lzzyExJXl6eivYkbV58fx25vW7dOpcem97JMoOk2Js2bYo777wTiYmJrj4kt3LkyBEkJSWVeO7JvhCyfMjnXsWWL1+u0u2tWrXCgw8+iLNnz7r6kHQlLS1Nva1du7Z6K3/jJAtQ/Lkmy62NGjXic62Cx83ku+++Q0REBNq1a4eJEyciKyvLRUeoP4WFhZgzZ47KLskyjj2fa26xIZ+9paamqgc1MjKyxPvl9r59+1x2XHonJ86vvvpKnRQknfnSSy+hT58+2LVrl1qfpcpJQCLKeu6ZPkZlL91IKrhJkyY4dOgQnnvuOVx33XXqD56Pjw88neyk/vjjj6N3797qJCrk+eTn54fw8PAS9+VzreLHTdxxxx1o3LixegG2Y8cOPPPMM6ruZN68efBkO3fuVEGILDVL3cj8+fPRpk0bbN++3W7PNY8MSsg2chIwkYInCVLkF/eHH37Avffe69Jjo+pt1KhR5uvt27dXz79mzZqp7En//v3h6aRGQl4csMbLPo/b/fffX+L5JkXp8jyTgFied56qVatWKgCR7NJPP/2E0aNHq/oRe/LI5RtJycmrq9KVwXI7KirKZcflbiQqbtmyJQ4ePOjqQ3EbpucXn3tVI8uH8nvM5x4wfvx4/Pbbb1i2bJkqRjSR55MsVV+4cKHE/flcq/hxK4u8ABOe/nzz8/ND8+bN0aVLF9XFJMXp77//vl2fa96e+sDKg7pkyZISaTy5LakpsszFixfVKwd5FUGWkeUH+SUt/txLT09XXTh87lnuxIkTqqbEk597UhMsJ1ZJoS9dulQ9t4qTv3G+vr4lnmuyBCF1YJ78XKvscSuLZAeEJz/fyiLnzdzcXPs+1wweas6cOarj4auvvjLs2bPHcP/99xvCw8MNSUlJrj403XryyScNy5cvNxw5csSwZs0aw4ABAwwRERGqep0uycjIMGzbtk1d5Ffs3XffVdePHTumPv7666+r59rPP/9s2LFjh+oqadKkiSE7O9vgqSp6zORjTz31lKril+fe4sWLDZ07dza0aNHCkJOTY/BUDz74oCEsLEz9Tp4+fdp8ycrKMt/ngQceMDRq1MiwdOlSw+bNmw09e/ZUF09W2eN28OBBw8svv6weL3m+ye9p06ZNDX379jV4smeffVZ1KMljIn+35LaXl5fhr7/+sutzzWODEvHhhx+qB9HPz0+1CK9fv97Vh6RrI0eONNSvX189Xg0aNFC35ReYSlq2bJk6sZa+SFurqS34hRdeMERGRqrAuH///oaEhASDJ6voMZOTxcCBAw1169ZVbYeNGzc2jBs3zuNfQJT1eMnlyy+/NN9HAt2HHnpItW4GBgYahg8frk7Anqyyxy0xMVEFILVr11a/n82bNzf85z//MaSlpRk82T333KN+9+Tvv/wuyt8tU0Biz+eal/xjXW6FiIiIyP48sqaEiIiI9IdBCREREekCgxIiIiLSBQYlREREpAsMSoiIiEgXGJQQERGRLjAoISIiIl1gUEJERES6wKCEiIiIdIFBCREREekCgxIiIiLSBQYlREREBD34f0TozhoZ5iDJAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_test, y_test_cat, verbose=0)\n",
        "print(f'Test loss: {loss:.4f} Test acc: {acc:.4f}')\n",
        "\n",
        "final_path = os.path.join(drive_path, 'mnist_cnn.keras')\n",
        "model.save(final_path)\n",
        "print('Saved model to', final_path)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.legend(); plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
